---
title: "ANOVA"
author: "Julio UQ"
date: "2/20/2022"
output:
  html_document: null
  toc: yes
  toc_depth: 2
  lang: en-EN
  pdf_document: default
  word_document: default
---

### 1. **ANOVA**
#### 1.1. **What is it and what is it for?**

An ANOVA test is a way to find out if survey or experiment results are significant between groups. If we only have two groups to compare, then we will speak of a comparison analysis between two samples, while if there are three or more groups, then we will speak of analysis of variance (**"One-way analysis of variance (ANOVA)**). This is called *"analysis of variance"*, since the differences between sources of variation (withing and among groups levels) are compared, and "one-way" because only one factor (treatment or grouping) is modified in the experiment.

Thus, ANOVA test starts with a ***"n"*** number of sampling and ***"k"*** number of categories, in order to answer if:

- There are significant differences between categories (**alternative hypothesis (Hi)**)
- There are not significant differences between categories (**null hypothesis (Ho)**)

#### 1.2. **Scuba-diving samplings.**

**For example**, we want to study the abundance in three distances from a marine protected area (MPA), one of which has a certain level of protection (fisheries). It is expected that by comparing the values of this zone with that of two others with similar characteristics, the fact will be evident. 

Random scuba-diving samplings have been carried out in a marine reserve (*Tabarca island, Alicante*). A set of different variables were visually measured: A) Species diversity, B) Total abundance and biomass, and C) Abundance and biomass per 4 species. The samplings have been carried out at three distances (near, medium and far) from the reserve, in 3 seasons of the year (summer, winter and autumn), repeating the sampling 7 days in each season, with 6 samplings each day. The objective of this example will be to check if there are significant differences for the abundance mean sampled as a function of the distance to the reserve.

- Are the differences observed between the groups **due to a real effect?** 
- Are the observed differences between the groups **due to random variation?**
- What would we find if we repeat the experiment?
- If there are differences, how significant are they?

```{r message=FALSE, include=FALSE}
library(tidyverse)
library(ggplot2)
library(sciplot)
setwd("/Users/macbookairjulio/Desktop/Statistical analyses/ANOVA directory")
```
```{r include = FALSE}
sampling_data <- read_csv("pescas.csv")
```
```{r}
summary(sampling_data)
```

**```IMPORTANT```** We must say to R which are the factors of the **ORTOGONAL DESING**: Here ***Distance and Season are Fix Factors*** which means that their effects are of researching interest, while ***Day and Replica are Nested Factors*** which means that their effects are not of researching interest but are important to calculate the least squares that will be used to obtain the p-value that will determine whether we reject the null hypotheses or not.

```{r}
cols <- c("Distance", "Season", "Day", "Replica")
sampling_data[cols] <- lapply(sampling_data[cols], factor)
```

Also, the Distance categories are ordered in order to look more visual friendly :)
```{r}
sampling_data$Distance <- factor(sampling_data$Distance, levels = c("Near", "Medium", "Far"))
```

##### 1.2.1. **Visualizing the structure of our data**

Let's start by **visualizing the structure of our data** graphically. A **boxplot** graphically summarizes the data showing 5 features that summarize the data set: the minimum, the first quarter (25th), the median, the third quarter (75th), and the maximum, as shown in the following figure:

In this repository the plots will be done using the R package ***"ggplot2"***.

```{r}
ggplot(data=sampling_data, aes(Distance, abu, colour = Distance)) +
  geom_boxplot() +
  stat_summary(fun=mean, geom="point", shape=18,
                  size=3, color="red") +
  ylab("Abundance (ind)")
```

Looking at the mean abundance of each distance. It is observed that near the reserve we find greater abundance values. At medium and far distances, it is seen that the mean abundances are quite similar. Although despite the fact that the maximum value in medium distance is greater than the maximum value in the far distance. The mean abundance in far distance is greater.

By now, one could think that there are differences between the abundance the reserve'distances, but it looks little bit blurred among medium and far distances. So, to check statistically if the observe differences are significant (Hi) or not (Ho). It will be carried out an analysis of the variance ANOVA.

##### 1.2.2. **Checking the requirement for ANOVA**

Linear models have certain properties, which must be validated to verify that our model is true and therefore the conclusions that we draw from the statistical analyzes are reliable. These are:

- **Homogeneity of variances** Here we consider that variances follow the homocedasticity. This means that the variance is constant (does not vary) at different levels of a factor, that is, between different groups. All y_(1,...,) y_n have the same standard deviation $\sigma$. In order to test if the distribution of our data cope with this requirement, we will perform a Bartlett (parametric) or Cochran (non-parametric) test.

```{r}
bartlett.test(sampling_data$abu~sampling_data$Distance) # p-value < 0.05
```
Since the *p-value is less than 0.05*, we reject the null hypothesis, so that at least one of the variances is significantly different. Which means that the variance of our data is not distributed homoscedastically.

To solve this situation, and to be able to continue with the ANOVA, **we must transform our data until this requirement is met**. The most common transformation are the ***logaritmic and square***.

If it were not fulfilled by transforming, the ANOVA would not be robust and we should opt for a non-parametric test such as the Krustal-wallis.

```{r eval= FALSE}
bartlett.test(sqrt(sampling_data$abu+1)~sampling_data$Distance) # p-value > 0.05
bartlett.test(log(sampling_data$abu+1)~sampling_data$Distance) # p-value > 0.05
```
Here with the square transformation would be enough to cope with the homocedasticity.

- **Normality** Here is used the **Kolmogorov-Smirnov test** to test the null hypothesis that a set of data comes from a Normal distribution. The Kolmogorov Smirnov test produces test statistics that are used (along with a degrees of freedom parameter) to test for normality.

```{r warning=FALSE}
Near <- filter(sampling_data, Distance == "Near")
Medium <- filter(sampling_data, Distance == "Medium")
Far <- filter(sampling_data, Distance == "Far")

ks.test(Near$abu, pnorm, mean(Near$abu), sd(Near$abu)) # p-value < 0.05
```
```{r eval = FALSE}
ks.test(Medium$abu, pnorm, mean(Medium$abu), sd(Medium$abu)) # p-value < 0.05
ks.test(Far$abu, pnorm, mean(Far$abu), sd(Far$abu)) # p-value > 0.05
```

The k-s test shows that the data distribution in near and medium distances follow the normality, but in the far distances not. So, since there are more than 30 entries in the data, we could go on with the ANOVA skipping this requirement, ***BUT*** alpha must be set to 001 (to make the ANOVA more restrictive).

- **Independence** It will depend on the sampling methodology. It is normally assumed that all sampling are independent. 

#### 1.2.3. One-way ANOVA.

Now that we have fulfilled the statistical whims to perform a sufficiently robust ANOVA, with which to draw conclusions that may have weight in the scientific community :)

Let's see if there are significant differences between the mean abundance at three distances of the marine protected area (MPA) of Alicante. The ANOVA equation looks like: **$X_{in} = \mu + D_{i}+e_{n}$**

```{r}
anova1 <- aov(sampling_data$abu~sampling_data$Distance)
summary(anova1)
```

The terms of the ANOVA are defined below:

- **The Df** column displays the degrees of freedom for the independent variable (the number of levels in the variable minus 1), and the degrees of freedom for the residuals (the total number of observations minus one and minus the number of levels in the independent variables).
- **The Sum Sq** column displays the sum of squares (a.k.a. the total variation between the group means and the overall mean).
- **The Mean Sq** column is the mean of the sum of squares, calculated by dividing the sum of squares by the degrees of freedom for each parameter.
- **The F-value** column is the test statistic from the F test. This is the mean square of each independent variable divided by the mean square of the residuals. The larger the F value, the more likely it is that the variation caused by the independent variable is real and not due to chance.
- **The Pr( >F) column** is the p-value of the F-statistic. This shows how likely it is that the F-value calculated from the test would have occurred if the null hypothesis of no difference among group means were true.

In this case, ***we have found a significant effect*** of the Distance variable (the p value was lower than 0.05). 

##### 1.2.4. Do a post-hoc test
ANOVA tells us if there are differences among group means, but not what the differences are. To find out which groups are statistically different from one another, you can perform a Tukey’s Honestly Significant Difference (Tukey’s HSD) post-hoc test for pairwise comparisons:

```{r}
TukeyHSD(anova1)
```

- **diff** means the differences in mean levels of Distance
- **lwr** corresponds to the minimum value of the confidence interval
- **upr** corresponds to the maximum value of the confidence interval
- **p adj** is the p-value of the F-statistic.

From the post-hoc test results, we see that there are statistically significant differences (p < 0.05) between Distance groups ```Near:Medium``` and between ```Near:Far``` but the difference between Distance group ```Medium:Far``` is not statistically significant. 

The differences between means in which the confidence interval that encompasses the lower and upper limits does not contain the value 0, are statistically significant with the Tukey method. In our case, there are significant differences between two categories.

**```Fancy points ;)```**Lets see this differences visually printing the TukeyHSD results in a graphic:

```{r}
plot(TukeyHSD(anova1))
```

**The significant groupwise differences** are any where the 95% confidence interval doesn’t include zero. This is another way of saying that the p-value for these pairwise differences is < 0.05.

##### 1.2.5. **Conclusions from the test**

- Our data meet with the requirement to perform the ANOVA (1º Independency, 2º Homocedasticity and 3º  Normality).
- There are differences statistically significant between the overall abundance found in near and medium distance (first significant differently group), and near and far distance (the second significant differently group), but not among medium and far distances.
- The significant differences look greater in the first group (*p-value = 0.0016254*) than in the second group with significant differences (*p-value = 0.0218749*).

#### 1.3. **Two-way ANOVA**
##### 1.3.1. **Adding interactions between variables**
 
Sometimes you have reasons to think that two of your independent variables have an interaction effect rather than an additive effect.

**For example**, in our abundance experiment, it is possible that ```Season``` period affects the amount of fish at every distance of the reserve (i.e., spawning seasons, nursery areas, migrations, etc.). This might influence the effect of ```Distance``` in a way that isn’t accounted for in the two-way model.

##### 1.3.2. **Visualizing the  data with one more factor**

To look for interactions effect between two independent variables, we will plot the data using the R package ***sciplot***.

```{r}
lineplot.CI(Distance, abu, group = Season, data = sampling_data, cex = 2,
            xlab = "Distance", ylab = "Abundance", cex.lab = 1.5, x.leg = 2.5,
            col = c("blue","red", "purple"), pch = c(16,16,16))
```

At first view, it looks that the interaction effect over the overall abundance in the Distance and Season turns out to occur between Far and Medium distances. To statistical check if this differences are significant, we will perform a ***Two-way ANOVA***. The Two-way ANOVA equation looks like: **$X_{ijn} = \mu + D_{i}+ S_{j}+e_{n}$**

In the two-way ANOVA example, we are modeling abundance as a function of type of Distance and Season. First we use ```aov()``` to run the model, then we use ```summary()``` to print the summary of the model

```{r}
anova2 <- aov(abu~Distance+Season, data = sampling_data)
summary(anova2)
```

Adding Season to the model seems to have made the model better: it reduced the residual variance (the residual sum of squares went from 14235 to 12676), and both Season and Distance are significantly difference (p-values < 0.05).

To test whether the interaction among two factors have significant effect in **ANOVA**, simply use an asterisk instead of a plus-sign in the model. Now the equation incorporate the interaction term: **$X_{ijn} = \mu + D_{i} + S_{j} + D*S_{ij} + e_{n}$**

```{r}
anova_interaction <- aov(abu ~ Distance*Season, data = sampling_data)
summary(anova_interaction)
```
In the output table, the *‘Distance:Season’* variable has a low sum-of-squares value and a low p-value, which means there is much variation that can be explained by the interaction between Distance and Season.

From this point, as we have found interaction effect. **We will analyze only the interaction**, since it will explain most of the abundance variance.

##### 1.3.3. **Do a post-hoc test**

```{r}
TukeyHSD(anova_interaction)
plot(TukeyHSD(anova_interaction))
```

##### 1.3.4. **Conclusions from the test**

- The variability of abundance is significantly different in combination of the effects of Season and Distance factor. Which means that the effect of one factor depend on the effect of the other.
- 11 combination of Distance and Season levels presented differences statistically significant (look TukeyHSD plot).


#### 1.4.**Summary of the chapter.**  

**In this chapter you have:** 

- Checked if the dataset meet with the requirement for performing an ANOVA (1º Homocedasticity, 2º Normality and 3º Independency).
- Visualized the relationship of the overall abundance regarding each level of Season and Distance.
- Performed an One-way ANOVA and examined for significant differences between groups.
- Performed a Two-way ANOVA and examine for significant differences between groups, and examine the effect of the interaction.


